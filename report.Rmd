---
title: "Math 155 Final Report"
author: Alfredo Gomez and Alfredo Gomez

date: "May 5, 2021"
output: pdf_document
header-includes:
  \DeclareMathOperator{\ARIMA}{ARIMA}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.align = "center", fig.show = "hold")

library(ggplot2)
library(TSA)
library(readr)
```

<!-- Downloading dataset -->
```{r, echo=FALSE}
data <- read_csv("sales_revenue_clean.csv")

totalSales <- ts(data$Tot_Sales,start=c(1990,1),frequency=12)
totalRev <- ts(data$Tot_Revenue,start=c(1990,1),frequency=12)
totalPrice <- ts(data$Tot_Price,start=c(1990,1),frequency=12)


rSales <- ts(data$R_Sales,start=c(1990,1),frequency=12)
rRev <- ts(data$R_Revenue,start=c(1990,1),frequency=12)
rPrice <- ts(data$R_Price,start=c(1990,1),frequency=12)

cSales <- ts(data$C_Sales,start=c(1990,1),frequency=12)
cRev <- ts(data$C_Revenue,start=c(1990,1),frequency=12)
cPrice <- ts(data$C_Price,start=c(1990,1),frequency=12)

iSales <- ts(data$I_Sales,start=c(1990,1),frequency=12)
iRev <- ts(data$I_Revenue,start=c(1990,1),frequency=12)
iPrice <- ts(data$I_Price,start=c(1990,1),frequency=12)

tSales <- ts(data$T_Sales,start=c(1990,1),frequency=12)
tRev <- ts(data$T_Revenue,start=c(1990,1),frequency=12)
tPrice <- ts(data$T_Price,start=c(1990,1),frequency=12)

oSales <- ts(data$O_Sales,start=c(1990,1),frequency=12)
oRev <- ts(data$O_Revenue,start=c(1990,1),frequency=12)
oPrice <- ts(data$O_Price,start=c(1990,1),frequency=12)
```

<!-- Custom functions -->
```{r}
plot_months <- function(series,  main = "title", ylab = "value", xlab = "Time") {
  Month=c('J','F','M','A','M','J','J','A','S','O','N','D')
  
  plot(series, main = main, ylab = ylab, xlab = xlab)
  points(series,pch=Month)
}
  
acf_pacf <- function(series, name = "Series"){
  acf. = acf(series, plot = FALSE)
  plot(acf., main = paste(name, "ACF"))
  pacf. = pacf(series, plot = FALSE)
  plot(pacf., main = paste(name, "PACF"))
}

stationary_test <- function(series){
  acf(series)
  pacf(series)
  print(runs(series))
  print(shapiro.test(series))
}
```


\begin{abstract}
We describe a time series model for the total electricity consumption of the United States from 2008 through 2018.
We found that that an $\ARIMA(0,1,1) \times \ARIMA(1,1,1)_{12}$ model best fits the data and passes the runs, Shapiro-Wilk, and Box-Ljung tests. 
Applying the forecast of the model to 2019 through the present, we see that the actual data falls within the 95th-percent confidence band of the forecast.
We take similar steps to model the electricity consumption of the commercial sector over the same time period and reach a similar $\ARIMA(0,1,1) \times \ARIMA(1,1,1)_{12}$ process.
However the model no longer passes the Shapiro-Wilk test and the actual electricity usage in March and April 2020 falls outside of the models forecast.
\end{abstract}

\section{Introduction}

\subsection{Dataset}
 
Our dataset includes the electricity consumption from 1990 to the present.\footnote{The dataset is maintained by the US Energy Information Administration and freely available at \url{https://www.eia.gov/electricity/data.php} as form EIA-861M.}
The data is broken down by state (including DC and Puerto Rico) and energy sector.
The energy sectors are residential, commercial, industrial and transportation/other (the other sector is recorded from 1990 - 2002 and the transportation sector is recorded from 2003 to the present).
The dataset measures the electricity consumption in four different ways: revenue in thousands of dollars, sales in MWh, price in cents/kWh, and number of customers (the number of customers is present in the dataset only after 2007).


\subsection{Data Exploration}
Graphs of the revenue, price, and sales of total electricity in the US are given below.
```{r, fig.show='hold', out.width="32%"}
Month=c('J','F','M','A','M','J','J','A','S','O','N','D')

plot(totalSales, main = "Total Sales")
points(totalSales,pch=Month)

plot(totalPrice, main = "Total Price")
points(totalPrice,pch=Month)

plot(totalRev, main = "Total Revenue")
points(totalRev,pch=Month)
```
Note that all three graphs exhibit seasonal patterns but also long term trends.
In particular, each decade of the data seems to behave differently.
The 90s are characterized by growing usage and a cheap price of electricity.
The 2000s are characterized by slower growth in the use of electricity and rising prices.
Finally the 2010s are characterized by flat electricity usage and slowly rising prices.
Another import trend in the sales and revenue graphs is a heteroscedastic increase in variance.
Since we are interested in modeling the total revenue with predictive power, heteroscedasticity is a problem.
While this can sometimes be addressed via power transformations the easiest thing in our case is to chop the dataset. We use only the data from 2008 onwards which we visually observed to be where the variance of the price of electricity began to stabilize. Since similar issues of heteroscedasticity appear across all of our available data, we figured this may due to some external factor changing the underlying process, and thus beleive we are justified in this decision.

We can also see the electricity use breakdown by sector.
To make the trends clearer over time, we show a 12 month moving average.
Note that the residential, commercial, and industrial sectors together is about 97% of the total revenue before 2003 and more than 97% of the total revenue after 2003, the remainder falls in the other or transportation sector, not shown on this chart.
```{r}
totalMA = filter(totalRev,rep(1,13)/13,sides=2) # 1 year MA
rMA = filter(rRev,rep(1,13)/13,sides=2) # 1 year MA
cMA = filter(cRev,rep(1,13)/13,sides=2) # 1 year MA
iMA = filter(iRev,rep(1,13)/13,sides=2) # 1 year MA

plot(cbind(totalMA/1e6,rMA/1e6,cMA/1e6, iMA/1e6),plot.type='single',col=4:1,lwd=2, ylab="sales (Millions of $)", main = "Electricity sales (12 month MA) by Sector")
legend(x = 'topleft', legend = c('Total', 'Residential', 'Commercial', 'Industrial'), col = 4:1, lwd = 2)
```

Interestingly, the 3 sectors all show their own trends. 
The industrial sector has little seasonal variation but is strongly impacted by the business cycle with revenues dropping significantly in great recession of 2008 - 2009 and during the lockdowns from COVID-19.

\section{Total Revenue Data}
The first series we will examine is the total revenue time series.

```{r, fig.show='hold', out.width="49%"}
totalRev2 = window(totalRev/1000000, start = c(2008, 1))


# hold actual data for later predictions
actual = window(totalRev2, start = c(2019,1))
totalRev2 = window(totalRev2, start = c(2008,1), end = c(2019,1))

plot_months(totalRev2, main = "Total Revenue (2008-2019)", ylab = "Revenue (Millions)", xlab = "Year")


```
 As noted earlier, due tot he odd behavior present throughout the data, we tightened our scope to only consider data past 2008. Additionally, we held out data past 2019 for the purposes of later forecasting. This resulted in a total of 132 data points. An initial observation we had was that there appeared to be a strong seasonal trend present in our data. The summer month seemed to exhibit relatively high values compared to the winter months. Additionally there appeared to be a slight upward trend in our data. 
 

\subsection{Model Specification}
 
 Our visual intuition is further confirmed by plotting the ACF and PACF of our data. 
 
```{r, fig.show='hold', out.width="49%"}
#acf and pacf
```

Plotting the ACF and PACF allows us to identify any autocorrelation present in our data, thus helping us determine an ARMA model to fit to our data. From the ACF our data is highly correlated at lag 1.0 (12 months), thus implying that our model will need a 12 month seasonal AR component. This is further exemplified by the PACF graph.

Our next step is to determine if our data needs to transformed. We do this by running a Box-Cox transformation test. 

```{r, fig.show='hold', out.width="49%"}
#boxcox and resutling transformation

# bc = BoxCox.ar(totalRev2)

logRev = log(totalRev2)
logActual = log(actual)

plot_months(logRev, main = "Transformed Revenue (2008-2019)", ylab = "Log Revenue", xlab = "Year")

acf(logRev)
pacf(logRev)
```


The resulting plot provides us with a possible power transformation that contains 0 and -1 within its confidence interval. However since 0 seems to be closer to the mean likelihood estimate for $\lambda$, we transformed our data by taking the logarithm. Note that the resulting time series still contains an upward trend after transforming. To account for this, we attempted to take a first and second difference of our data and evaluate them with their respective ACF's.


```{r, fig.show='hold', out.width="49%"}
diffRev = diff(logRev)
plot_months(diffRev, main = "First Difference of Log Revenue", ylab = "First Difference of Log Revenue", xlab = "Year")
acf(diffRev, main = "First Difference ACF")


plot_months(diffRev, main = "Second Diff of Log Revenue", ylab = "Second Difference of Log Revenue", xlab = "Year")
acf(diff(diffRev), main = "Second Diff ACF")
```

Visually, both of approaches were able to detrend our data and this is reflected in the ACF's by the autocorrelations being near or within our margins for most of the lags. However upon close inspection, it appears that there are a few lags resulted in higher autocorrelations within the second difference ACF, implying that this may be over-differencing the data. Hence we will proceed any further analysis using the first difference.

Moreover, we still observe a significant autocorrelation spike at lag 12 after the first difference. In order to account for this, we perform a seasonal difference to our first difference.

```{r, fig.show='hold', out.width="49%"}
seasDiffRev = diff(diffRev, lag = 12)
plot_months(seasDiffRev, main = "First Non-Seasonal and Seasonal Difference of Log Revenue", ylab = "First Non-Seasonal and Seasonal Difference", xlab = "Year")
acf(seasDiffRev, main = "ACF")
pacf(seasDiffRev)
```

Now we see that that any seasonality has been largely account for. To finally determine our candidate models, we run ARMA-Subsets and EACF for the first non-seasonal and seasonal difference of revenue. Firstly, the ARMA subset for the first non-seasonal and seasonal difference suggested a model with no non-seasonal AR terms, but possibly a seasonal AR term. Additionally it suggests a seasonal MA term in addition to a few non-seasonal AR terms. Thus some of the seasonal components were $(1,1,2)_{12}$, $(1,1,0)_{12}$ and $(0,1,2)_{12}$. Looking at the EACF, it seemed fairly possible that our model could contain up to two non-seasonal MA terms and at most one AR component depending on which values we count as false positives within the plot. 

```{r, fig.show='hold', out.width="49%"}
eacf(seasDiffRev, ar.max = 12)
plot(armasubsets(diffRev, nar = 12, nma = 12))
```

Using this information we reduced our search to the following models: $ARIMA(0,1,1)\times(0,1,2)_{12}$, $ARIMA(0,1,0)\times(0,1,1)_{12}$, $ARIMA(0,1,1)\times(0,1,2)_{12}$, $ARIMA(0,1,2)\times(1,1,1)_{12}$.

\subsection{Model Diagnostics}

Moving forward with the four models previously identified, we will train them on our data and evaluate their performance using a series of tests to assess randomness, normality and independence.

```{r, fig.show='hold', out.width="49%"}
model1 = arima(logRev, order = c(0,1,1), seasonal = list(order=c(0,1,2),period= 12))
model1
model2 = arima(logRev, order = c(0,1,0), seasonal = list(order=c(0,1,1),period= 12))
model2
model3 = arima(logRev, order = c(0,1,1), seasonal = list(order=c(0,1,2),period= 12))
model3
model4 = arima(logRev, order = c(0,1,2), seasonal = list(order=c(1,1,1),period= 12))
model4
```

From the models themselves it is worth noting that Models 1, 3, and 4 had similar scores for AIC, whereas Model 2 appeared to score a few points lower. Additionally most, if not all, coefficients appear to be statistically significant since zero is more that a standard error away from the derived value.

TODO: Add table for of performance

From the summary table of diagnostics, we note that Model 1 and Model 3 both fail the runs the test, thus we must reject the hypothesis that the residuals are independent. However for examples, there is insufficient evidence to reject the hypotheses that the residuals are normally distributed. Additionally, the Box-Ljung test fails to reject the hypotheses that the models do not show lack of fit. In the end, the lack of independence within the residuals was sufficient for us to reject these two models and more closely consider the remaining.

Both Model 2 and Model 4 passed all tests. However, we went with Model since it had a higher p-value under the Shapiro Test and due to its lower AIC score. For reference, we have included a plot of the historical data (black) along side the model (red) as well as the residuals resulting from our model choice.

```{r, fig.show='hold', out.width="49%"}
plot(fitted(model4), col = 'red', main = "Plotting Log Revenue With Model 4", ylab = "Log Revenue", xlab = "Years")
lines(logRev, pch = 3)

model <- model4
res = rstandard(model)
plot_months(res, main = "Standardized Residuals of Model 4", ylab = "Residuals")
hist(res, main = "Histogram of Standardized Residuals")
```


\subsection{Forecasting}

To forecast future observations, we use the forecast and predict functions to forecast our Model 2 using our held out data from 2019 and 2020 at the 95% confidence level. 

We first plot our model forecasts with the historical data. The solid black line represents the historical data while the dotted line represent the predicted values from our model. The red outline corresponds to our 95% confidence interval

```{r, fig.show='hold', out.width="49%"}
num = length(actual)

res = plot(model,n.ahead=num, n1 = c(2016,2), col = "red", main = "ARIMA(0,1,2)x(1,1,1)_12 Forecast", ylab ="Log Revenue", xlab = "Year")
lines(logActual,pch=3) 
abline(h=coef(model)[names(coef(model))=='intercept'])
```

Next we plot the model's predictions for the future. The modelâ€™s forecasts are slightly higher than the actual values, however, these appear to be within forecast limits, so while it is noticable, it is not statistically significant.

```{r}
num = length(actual)
res = plot(model,n.ahead=36, col = "red", main = "Beyond 2020", ylab = "Log Revenue", xlab = "Year")
abline(h=coef(model)[names(coef(model))=='intercept'])
```

TODO: Consider adding in table with predected values

\section{Commercial Revenue Data}
The second series we will examine is the commercial revenue time series.
```{r, fig.show='hold', out.width="49%"}
cRev <- ts(data$C_Revenue/1000000,start=c(1990,1),frequency=12)
plot_months(cRev, main = "Commercial Revenue (1990-2020)", ylab = "Revenue (Millions)", xlab = "Year")

cRev2 = window(cRev, start = c(2008, 1))

# hold actual data for later predictions
actual = window(cRev2, start = c(2019,1))
cRev2 = window(cRev2, start = c(2008,1), end = c(2019,1))

plot_months(cRev2, main = "Commercial Revenue (2008-2019)", ylab = "Revenue (Millions)", xlab = "Year")
```

As in the total revenue series, we remove the data from the 1990s and 2000s as the underlying electricity economy was growing much faster then compared to now.
We also hold out the 2019 and 2020 data for forecasting.
Therefore, we model on data from January 2008 to December 2018, a total of 132 data points.
Another similarity with the total revenue series is that the data has a strong seasonal component.

Looking at the plots, we also see some strong outlier seasons. 
For example the 2009 summer showed unusually low revenue relative to other summers while the 2014 winter was unusually high.
We believe that this is due to weather effects, and these were likely a cool summer and warm winter respectively.\footnote{A U.S. Energy Information Administration post, explaining the seasonal variability in more detail can be found at \url{https://www.eia.gov/todayinenergy/detail.php?id=10211}}

```{r, fig.show='hold', out.width="49%"}
acf_pacf(cRev2, "Commercial Revenue")
```

Looking at the autocorrelation function, we can confirm that the data shows strong seasonality.
The partial autocorrelation shows two significant correlations at lags 1 and 2 suggesting an AR(2) process but there are several additional spikes, most notably at lags 6 and 9.

```{r, out.width= "65%"}
bc = BoxCox.ar(cRev2, lambda = seq(-0.5, 1.5, 0.1))
```

We considered taking a transformation but a Box-Cox plot reveals that none is necessary as $\lambda = 1$ (indicating the identity transformation) as within the 95% confidence interval of the plot.

Next we explore, the impact of differencing our data.
Since there are strong seasonal affects these need to be removed either through a seasonal regressor or a seasonal difference.
```{r, fig.show = "hold", out.width="32%"}
cRev_diff01 = diff(cRev2, lag = 12)
cRev_diff10 = diff(cRev2)
cRev_diff11 = diff(cRev_diff01)
plot(cRev_diff10, main = "First Difference", ylab = "")
plot(cRev_diff01, main = "Seasonal First Difference", ylab = "")
plot(cRev_diff11, main = "First Difference and Seasonal First Difference", ylab = "")
```

Indeed, the first difference alone is clearly leaves the seasonal patterns intact.
The first seasonal difference and the combined first seasonal and non-seasonal difference both succeed in removing the seasonal patterns so we we will proceed to consider ARIMA models with one seasonal difference and either zero or one non-seasonal differences.

\subsection{Model Specification}

To better understand the correlations in our series we recompute the ACF and PACF of our differenced data.

```{r, out.width="49%"}
acf_pacf(cRev_diff01, name = "Seasonal Difference of Commercial Revenue")
```

The partial autocorrelation function has a large spike at lag 1 that strongly suggests including an AR(1) term in the model.
Since the autocorrelation function looks somewhat like a decaying exponential that an AR(1) process produces we can consider modeling the series as an $\ARIMA(1,0,0) \times (0,1,0)_{12}$ process.
We'll use this as model 1.
Next we consider the series with both a seasonal and non difference applied.

```{r, out.width="49%"}
acf_pacf(cRev_diff11, name = "Seasonal Difference of Commercial Revenue")
```

This set of graphs is more difficult to interpret although both the ACF and the PACF have spikes at lag 12.
The graphs also have spikes at lag 1 although they are both close to the significance threshold.
Since there is no clear model suggested by the ACF and PACF we now seek additonal candidate models using the armasubsets tool in R.

```{r, out.width = "75%"}
armas = armasubsets(cRev_diff01, nar = 12, nma = 12)
plot(armas)
```

The top 2 row of the plots suggest two further strong candidate models (models 2 and 3), an $\ARIMA(2,0,0) \times (1,1,0)_{12}$ and $\ARIMA(1,0,0) \times (0,1,1)_{12}$.
Note that model 3 is similar to the model 1 we guessed at from the ACF and PACF plots but also has a seasonal MA term.
We can also see that our model 1 shows up as the second to last row on the armasubsets plot, so we can infer that it may be a substantially worse model.
Next we

```{r, out.width = "75%"}
plot(armasubsets(cRev_diff11, nar = 12, nma = 12))
```

The top 3 models suggested by
\subsection{Model Diagnostics}

\subsection{Forecasting}

\section{Discussion}

\section{Conclusion}

\section{References}
